# ğŸ“˜ Fencing Pose Classification Pipeline Documentation

This guide helps you set up and run a fencing move classification project using MediaPipe for pose extraction and a Transformer-based PyTorch model for classification.

---

## ğŸ”§ 1. Installation Requirements

### Python Version:

* Python 3.8 or newer

### Install required libraries:

```bash
pip install mediapipe opencv-python torch torchvision yt-dlp pandas scikit-learn matplotlib
```

---

## ğŸ“ 2. Folder Structure

```
project_root/
â”œâ”€â”€ frame/               # Input folder for .mp4 videos
â”œâ”€â”€ pose_data/           # Stores extracted pose .npy files + labels.csv
â”œâ”€â”€ scraped_videos/      # Stores YouTube-scraped videos (optional)
â”œâ”€â”€ extract_poses.py
â”œâ”€â”€ fencing_scrapper.py
â”œâ”€â”€ labels_script.py
â”œâ”€â”€ merge_pose_data.py
â”œâ”€â”€ pose_dataset.py
â”œâ”€â”€ pose_landmark.py
â”œâ”€â”€ pose_transformer.py
â”œâ”€â”€ train_model.py
â”œâ”€â”€ video.py
â”œâ”€â”€ visualize_frames.py
```

---

## ğŸ“¹ 3. \[Optional] Scrape Fencing Videos from YouTube

Run this to auto-download and label fencing videos:

```bash
python3 fencing_scrapper.py
```

This saves videos to `scraped_videos/` and labels to `scraped_videos/labels.csv`.

Then move videos to the main video folder:

```bash
mv scraped_videos/*.mp4 frame/
cp scraped_videos/labels.csv pose_data/
```

---

## ğŸ•´ï¸ 4. Extract Poses from Video Frames

Run this to extract 3D pose landmarks from all `.mp4` videos:

```bash
python3 extract_poses.py
```

This saves pose arrays (`*.npy`) into the `pose_data/` folder.

---

## ğŸ·ï¸ 5. Create a Labels File

If you named videos like `thrust_clip1.mp4`, run:

```bash
python3 labels_script.py
```

This generates `pose_data/labels.csv` with auto-labeled rows:

```
filename,label
thrust_clip1_pose.npy,thrust
parry_clip2_pose.npy,parry
```

---

## ğŸ“¦ 6. Merge All Pose Files

Run this script to combine all individual `.npy` pose files into a single sequence file:

```bash
python3 merge_pose_data.py
```

It creates `pose_data/pose_sequences.npy`

---

## ğŸ§  7. Train the Pose Transformer

```bash
python3 train_model.py
```

This:

* Loads labeled `.npy` files
* Trains a Transformer classifier
* Saves the model as `pose_model.pth`
* Prints label mapping and sample predictions

---

## ğŸ§ª 8. Evaluate Results

The training script automatically prints predictions on sample inputs. If everything works:

```
Sample 1: True = thrust, Predicted = thrust
Sample 2: True = parry, Predicted = roll
...
```

---

## ğŸ‘€ 9. Visualize Frames

Use this script to view random frames:

```bash
python3 visualize_frames.py
```

---

## ğŸ›  Troubleshooting

* If all predictions are one label â†’ check `labels.csv` balance
* If pose extraction fails â†’ ensure videos are readable `.mp4` and not corrupted
* Update `yt-dlp` if scraping fails:

```bash
pip install -U yt-dlp
```

---
run sequence 
1. extract_poses
2. labels_script
3. pose_dataset
4. pose_landmark
5. merge_pose
6. train_model
8. video.py and viualize
9. pose_transformer

May need to download 
1. pytorch

2. other dependencies

